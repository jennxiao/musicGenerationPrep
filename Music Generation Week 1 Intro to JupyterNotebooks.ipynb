{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1: Intro to Jupyter Notebooks and ML Models\n",
    "**For Codeology's Music Generation Project Fall 2019 by Jennifer XIao and ALma Pineda**\n",
    "\n",
    "**With help from Codeology's ML workshop Jupyter notebook authored [Calvin Chen](mailto:chencalvin99@berkeley.edu), [Micah Harrison](mailto:mharrison08@berkeley.edu), and [Sai Kapuluru](mailto:saikapuluru@berkeley.edu).**\n",
    "\n",
    "### Table Of Contents\n",
    "* [Jupyter Notebook guide](#intro)\n",
    "    * [Python Review](#python)\n",
    "* [Machine Learning and modeling](#machine)  \n",
    "    * [Linear Regression](#linear)\n",
    "    * [Ordinary Least Squares](#ordinary_least_squares)\n",
    "    * [Example Model](#making_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Jupyter Notebook How To:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a code cell. Code cells allow you to enter and run code Run a code cell using Shift-Enter or pressing the button in the toolbar above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Python world!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "message = \"Hello Python world!\"\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortcuts \n",
    "\n",
    "Alt-Enter runs the current cell and inserts a new one below.\n",
    "\n",
    "Ctrl-Enter  run the current cell and enters command mode.\n",
    "\n",
    "Shift-Enter runs the current cell and \"moves\" you to the next one\n",
    "\n",
    "\n",
    "### Restarting the kernals\n",
    "The kernel maintains the state of a notebook's computations and variables. You can reset this state (e.g. if the kernal gets stuck on a computation or loses wifi) by restarting the kernel. Do this by going up to the Toolbar -> Kernal -> Kernal Restart.... Once you restart your kernel you will need to rerun all the cells you previously had run.\n",
    "\n",
    "You can also rerun lots of cells all at once by clicking on a cell of code and going to the toolbar: Cell -> Cell and Rerun All & Above..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='python'></a>\n",
    "## Helpful Basic Python How To:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "We can use variables to hold values. These variables can hold different types of values. You can use type() to see what the variable's type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 1.0\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"Codeology is da bomb\"\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Codeology is da bomb'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "w = 3 \n",
    "y = 8\n",
    "z = w + y \n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries\n",
    "Think of a dictionary as an unordered set of key: value pairs, with the requirement that the keys are unique (within one dictionary). You can use keys to retrieve the values associated with that key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'parameter1': 1.0, 'parameter2': 2.0, 'parameter3': 3.0}\n",
      "1.0\n",
      "2.0\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "params = {\"parameter1\" : 1.0,\n",
    "          \"parameter2\" : 2.0,\n",
    "          \"parameter3\" : 3.0,}\n",
    "\n",
    "print(type(params))\n",
    "print(params)\n",
    "print(params[\"parameter1\"])\n",
    "print(params[\"parameter2\"])\n",
    "print(params[\"parameter3\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists\n",
    "Lists are the most commonly used data structure. Think of it as a sequence of data that is enclosed in square brackets and data are separated by a comma. Each of these data can be accessed by calling it's index value.\n",
    "\n",
    "Lists are declared by just equating a variable to '[ ]' or list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['machine learning', 'data science', 'berkeley']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "In python, Indexing starts from 0. Thus now the list x, which has two elements will have apple at 0 index and orange at 1 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine learning'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ai buzzword!'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0] = \"ai buzzword!\"\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'berkeley'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###to go backwards in a list \n",
    "x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ai buzzword!', 'data science', 'berkeley']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### list inside of a list\n",
    "y = [x]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing \n",
    "\n",
    "get part of a list by defining the index values of the first element and the last element from the parent list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n",
      "[4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num = [0,1,2,3,4,5,6,7,8,9]\n",
    "print(num[0:4])\n",
    "print(num[4:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built in List Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0\n",
      "9\n",
      "[1, 2, 3, 5, 4, 7]\n"
     ]
    }
   ],
   "source": [
    "#Find the length\n",
    "print(len(num))\n",
    "\n",
    "#Find the min value\n",
    "print(min(num))\n",
    "\n",
    "#Find the max value\n",
    "print(max(num))\n",
    "\n",
    "#Concatenate two lists \n",
    "x = [1,2,3] + [5,4,7]\n",
    "print(x)\n",
    "\n",
    "#Check if an element is in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for x in range(4):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameter1 = 1.0\n",
      "parameter2 = 2.0\n",
      "parameter3 = 3.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#iterate through the key value pairs from the dictionary we defined earlier\n",
    "for key, value in params.items():\n",
    "    print(key + \" = \" + str(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x*x \n",
    "\n",
    "# You can return multiple  values\n",
    "def powers(x):\n",
    "    return x ** 2, x ** 3, x ** 4\n",
    "\n",
    "#You don't have to have a return value\n",
    "def split_up_string(x):\n",
    "    for s in x:\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='machine'></a>\n",
    "## Intro to ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Ideas**\n",
    "\n",
    "Models describe classes of things and relationship between things. For example, you can have a a model to describe spam vs not-spam emails, cats vs dogs, female vs male. Or you could have a model describe the relationship between mass, acceleartion and force in Newton's Second Law. \n",
    "\n",
    "Once you have a model, you can use them to make predictions. Maybe you want to create an email spam-classifier. Or maybe you want to predict someone's weight based on their gender and height.\n",
    "\n",
    "BUT, there is one thing you should always remember. Just because you can make a model and use it to accurately predict the value of one variable based on the value of the other, it doesn't mean that one causes the other. You've probably heard this before: **correlation != causation**. A classic example is the relationship between ice cream sales and murder rates. Turns out, when ice cream sales rise, so do murder rates. Does this mean ice cream *causes* people to commit murder? Or get murdered? Nope!\n",
    "\n",
    "*** One of the most basic models is one that describes a linear relationship between two things. So below we are going to use the linear model to understand the fundamental ideas behind modeling in ML. ***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='linear'></a>\n",
    "### Linear Regression\n",
    "\n",
    "This is the fancy term used to describe the method behind making a linear model. \n",
    "\n",
    "**Simple linear regression** is a special case of linear regression in which you only have one explanatory variable. As the name suggests, it models the relationship as a *line*. You may be familiar with the slope-intercept form of a line, and that's exactly how the linear model looks!\n",
    "\n",
    "$$y = mx+b$$\n",
    "\n",
    "$y$ is the **response** or **dependent** variable we're trying to predict.\n",
    "$x$ is an **explanatory** or **independent** variable used to predict $y$. \n",
    "\n",
    "If we were trying to create a model that uses height to predict weight, $y$ would represent weight, while $x$ represents height. Using known $x$'s, we want to accurately predict $y$ by using the right $m$ and $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But, given a bunch of x's and y's, how do we know what the right m and b are?**\n",
    "\n",
    "In high school labs, you probably plugged these values into excel and created a **Best Fit Line**, and now we can unpack the magic that happens behind the scenes from a machine learning perspective.\n",
    "\n",
    "\n",
    "The line of best fit is the line that \"fits\" the data the best. But creating the \"best\" or most accurate model involves defining a *loss function*. The **loss function** is a function that measures how far off our model's estimated values are from the true values. We want our model to be as accurate as possible, so that means we want to minimize the error our model makes in predicting values. In other words, we want to minimize the loss between the points we have and the line we are creating for the model\n",
    "\n",
    "<img src='https://www.cs.toronto.edu/~frossard/post/linear_regression/lreg.jpg' width=400>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ols'></a>\n",
    "### Ordinary Least Squares\n",
    "\n",
    "In linear regression, we use **ordinary least squares (OLS)**, which minimizes the sum of squared residuals. A **residual** is the difference between the predicted value and the observed value for a given $x$. For a given observation $(x_i, y_i)$, the residual $e_i$ is calculated as:\n",
    "\n",
    "$$ \\underbrace{e_{i}}_{error} = \\underbrace{y_i}_{actual} - \\underbrace{\\hat{y_i}}_{predicted} = y_i - mx_i - b$$\n",
    "\n",
    "**Question**: Can you think of why we would want to *square* the residuals and sum them instead of just minimizing their sum?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to minimize the **residual sum of squares (RSS)**, what we're actually going to minimize is this:\n",
    "\n",
    "$$\\textit{RSS} = \\sum_{i=0}^n {e_i}^2 = \\sum_{i=0}^n (y_i - mx_i - b)^2$$\n",
    "\n",
    "By minimizing this function, we can solve for slope $m$ and the intercept $b$. The actual calculations for deriving the formulas that define these coefficients requires a bit of calculus, so we'll skip that part for now, but if you want to look into it more on your own you can check out [this link](http://seismo.berkeley.edu/~kirchner/eps_120/Toolkits/Toolkit_10.pdf)! For now, we'll just tell you that $m$ and $b$ can be solved as:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\hat{b}&=\\bar {y}-\\hat{m}\\,{\\bar{x}},\\\\\n",
    "\\hat{m}&=\\frac{\\sum _{i=1}^{n}(x_{i}-\\bar{x})(y_{i}-\\bar {y})}{\\sum _{i=1}^{n}(x_{i}-\\bar{x})^2}\\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "This is pretty complicated! Luckily, you don't need to know any of this to make a linear model, but this is here for reference if you're interested in the math behind what we'll be getting into today. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='making_model'></a>\n",
    "### Example Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to find the dataset we found to work with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from plotting import overfittingDemo\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "\n",
    "mpg = pd.read_csv(\"./data/mpg.csv\", index_col=\"name\") # load mpg dataset\n",
    "mpg = mpg.loc[mpg[\"horsepower\"] != '?'].astype(int) # remove columns with missing horsepower values\n",
    "mpg_train, mpg_test = train_test_split(mpg, test_size = .2, random_state = 0) # split into training set and test set\n",
    "mpg_train, mpg_validation = train_test_split(mpg_train, test_size = .5, random_state = 0)\n",
    "mpg_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we've chosen the mpg dataset, which tells us various attributes of different cars, including a car's make and model, miles per gallon, number of cylinders, weight, and more! We're going to be trying to see which features affect a car's mpg, and our goal is to create a model that accurately predicts mpg given other attributes of the car.\n",
    "\n",
    "You'll notice that we separated the mpg data into two separate dataframes, mpg_train and mpg_test. We'll get into why in a later part of today's lecture, but for now, make sure to do all of your analysis and model creation on the mpg_train dataset!\n",
    "\n",
    "Try making some scatter plots of different variables as your x and mpg as your y using the mpg_train dataset below!\n",
    "\n",
    "Hint: Hitting shift-tab with the cursor on the name of a function will bring up helpful documentation about how to use the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mpg_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-515f292f1276>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmpg_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mpg_train' is not defined"
     ]
    }
   ],
   "source": [
    "mpg_train.plot.scatter(\"mpg\", 'weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn's linear_model module makes it really easy to make linear models! There's a lot of different types of linear models implemented in the linear_model module, which you can take a look at  [here](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model) if you're interested.\n",
    "\n",
    "Today we'll be using LinearRegression, which we've imported for you in the cell below. Try reading the documentation to figure out what the fit() function expects as input to correctly fit our model to the mpg_train data!\n",
    "\n",
    "Hint: if you want to select a subset of columns from a dataframe, pass in a list of column names, like df[['col1', 'col2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our linear regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "X = mpg_train[['displacement']]\n",
    "Y = mpg_train[['mpg']]\n",
    "\n",
    "# TODO: Fit the model to the data\n",
    "\n",
    "\n",
    "# TODO: extract the coefficient and the intercept\n",
    "coef = \n",
    "intercept = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice that, while the `intercept_` is a single scalar value, `coef_` returns an array. This is because you can choose to fit your model to multiple explanatory variables (hence the list form of `feature_cols`). When you define multiple explanatory variables, the `coef_` will contain a separate coefficient for each explanatory variable you chose! You'll be able to explore that in a bit, but for now let's take a look at what our linear model looks like relative to our original data.\n",
    "\n",
    "We've provided the skeleton for a helper function called `overlay_simple_linear_model`. Try to fill out the function so that it plots a scatterplot with the linear model overlaid on top.\n",
    "\n",
    "*Hint:* If you press `tab` after a `[object].` or `[package].`, Jupyter will show you a list of valid functions defined for that object type or package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_simple_linear_model(data, x_name, y_name, linear_model):\n",
    "    \"\"\"\n",
    "    This function plots a simple linear model on top of the scatterplot of the data it was fit to.\n",
    "    \n",
    "    data(DataFrame): e.g. mpg_train\n",
    "    x_name(string): the name of the column representing the predictor variable\n",
    "    y_name(string): the name of the column representing the dependent/response variable\n",
    "    linear_model\n",
    "    \n",
    "    returns None but outputs linear model overlaid on scatterplot\n",
    "    \"\"\"\n",
    "    \n",
    "    x = np.arange(max(data[x_name])).reshape((-1, 1)) # an array of integers between 0 and the maximum value of the x_name column\n",
    "    y = linear_model.____ # replace ___ with correct function \n",
    "    \n",
    "    \n",
    "    data.plot.scatter(...) # scatter plot of x_name vs. y_name\n",
    "    \n",
    "    plt.plot(x, y, color='red')\n",
    "    plt.title(\"Linear Model vs. Data: \" + x_name + \" vs. \" + y_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mpg_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-877d8a455e75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# If you wrote the function above correctly, this should produce a scatterplot with a line through it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moverlay_simple_linear_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmpg_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mpg_train' is not defined"
     ]
    }
   ],
   "source": [
    "# If you wrote the function above correctly, this should produce a scatterplot with a line through it\n",
    "overlay_simple_linear_model(mpg_train, ..., \"mpg\", linear_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
